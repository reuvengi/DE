## Примеры требований:

MLOps - построение пайплайна решения задач ML от сбора фичей до выкладки моделей в production
Создание, настройка, мониторинг, оптимизация и документирование ETL-процессов;
Обеспечение работоспособности промышленного кластера Hadoop;
Обеспечение работоспособности систем, отвечающих за транспортировку данных (kafka, airflow);
Разрабатывать систему поиска аномалий;
Развивать in-house систему Machine Learning Pipelines, сервисы для realtime предсказаний;
Разрабатывать внутреннюю систему статистики, обслуживающую более 2 миллионов событий в секунду;
* определять с бизнесом, какие данные нужны для решения задач и оперативно строить пайплайны по загрузке данных в Data Lake на регулярной основе;
* строить витрины под аналитические цели, выбирая оптимальный формат и структуру хранения данных;
* помощь Data Scientist'истам в разработке и выводе в продакшн моделей машинного обучения, как в батче, так и в реал-тайм;
* применять техники потоковой обработки данных для решения реал-тайм задач;

## Популярные требования к технологиям:

Хранилища: Clickhouse, Vertica, Hadoop, Greenplum

СУБД: Postgres

Языки: Python, Golang, Scala

Batch processing: Airflow, Luigi

Stream processing: Kafka

OS: Linux, Docker, K8s

Processing: Spark

BI: Tableau, Power BI

## Анализ

Проанализировав рынок data engineer russia, краткое резюме:

### Что надо делать

* ETL -самое важное практически везде их надо разработывать поддерживать, мониторить
* Моделировать хранилище, проектирование и разработка витрины
* Знать основы ML - потому что строить ML pipelines от сбора данных до выкладки в прод, где-то надо делать anomaly detection
* Поддержка и мониторинг Hadoop, Kafka, Airflow, ClickHouse, Vertica, GreenPlum
* Практически везде есть stream processing - поэтому важное место уделяется Kafka 


### Что надо знать

* TOP языки Python SQL Scala Golang - практически везде встречается
* TOP stream processing - Kafka
* TOP Оркестрация ETL - Airflow
* TOP Batch Processing - Spark
* TOP хранилища - Hadoop, Clickhouse, MPP - Vertica, Greenplum

### Цель на курс и для развития в данной области

* Научится разработке ETL, научится проектировать и разрабатывать витрины и хранилища DWH и Datalake, научится основам ML, практическая работа с Hadoop, Datalake, ClickHouse, Vertica, Python/Scala, Kafka, AirFlow, Spark, Tableau - сделать минимальное портфолио
